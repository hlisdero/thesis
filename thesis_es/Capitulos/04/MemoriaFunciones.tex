\section{Memoria de las funciones}

A continuación procederemos a explorar en detalle las características de memoria de la función
\acrshort{MIR}. Es importante reconocer que la necesidad de registrar los valores que se asignan entre
lugares de memoria en la \acrshort{MIR} surge de los requisitos de la detección de bloqueos y
señales perdidas. En términos más sencillos, nos vemos obligados a modelar la memoria
únicamente porque es necesario realizar un seguimiento de las variables de sincronización
soportadas por el proceso de traducción.

El traductor debe realizar un seguimiento de las variables de los siguientes tipos:

\begin{itemize}
  \item Mutexes (\Rustinline{std::sync::Mutex}).
  \item Mutex guards (\Rustinline{std::sync::MutexGuard}).
  \item Join handles (\Rustinline{std::thread::JoinHandle}).
  \item Condition variables (\Rustinline{std::sync::Condvar}).
  \item Agregados (\emph{Aggregates}), es decir, contenedores/wrappers como \Rustinline{std::sync::Arc} o tipos que contienen varios
        valores como tuplas o un tipo estructurado (\Rustinline{struct}).
\end{itemize}

Antes de llamar a los métodos de estos tipos de variables de sincronización, se crean
referencias inmutables o mutables a la ubicación de memoria original. El traductor debe saber
de algún modo qué variable de sincronización específica está detrás de una referencia
determinada. Conocer el tipo de la ubicación de memoria \emph{no} es suficiente, el \emph{valor} debe ser
fácilmente accesible para que el traductor modifique el modelo de red de Petri de la variable de
sincronización específica.

\subsection{Un ejemplo guiado para introducir los desafíos}

Para ilustrar la situación descrita anteriormente, considere el programa Rust mostrado en el
Listado \ref{lst:double-lock-deadlock}. Se trata de nuevo de uno de los programas de ejemplo que se encuentran en el
repositorio. Como debería ser evidente para el lector, este programa se bloquea cuando se
ejecuta.
La razón es que la función \Rustinline{std::sync::Mutex::lock} está siendo invocada dos veces sobre el mismo mutex.
Para detectar este deadlock, el traductor debe ser capaz, como mínimo, de identificar que la invocación de \Rustinline{lock}
tiene lugar sobre el mismo mutex.

\begin{listing}[!htb]
  \begin{minted}{Rust}
    fn main() {
      let data = std::sync::Mutex::new(0);
      let _d1 = data.lock();
      let _d2 = data.lock(); // cannot lock, since d1 is still active
    }
  \end{minted}
  \caption{Un deadlock causado por llamar a lock dos veces sobre el mismo mutex.}
  \label{lst:double-lock-deadlock}
\end{listing}

Observe ahora un extracto de la \acrshort{MIR} del mismo programa erróneo en el Listado \ref{lst:double-lock-deadlock-mir}.
Se han eliminado los comentarios para mayor claridad. En BB0 el mutex se crea mediante una llamada
a \Rustinline{std::sync::Mutex::new}. El nuevo mutex es el valor de retorno de la función. Se asigna a la
variable local \Rustinline{_1}. A continuación, la ejecución continúa en BB1. Concéntrese en la primera
sentencia de BB1: Una referencia inmutable a la variable local \Rustinline{_1} se almacena en \Rustinline{_3}. A
continuación, la referencia se traslada a la función \Rustinline{std::sync::Mutex::lock}. Esta referencia es
consumida por \emph{lock}, es decir, la variable local \Rustinline{_3} no se utiliza en ningún otro lugar de la \acrshort{MIR}
porque, a partir de ese momento, la propiedad de la referencia se transfiere a la función
\Rustinline{std::sync::Mutex::lock}.

\begin{listing}[!htb]
  \begin{minted}{Rust}
    fn main() -> () {
      let mut _0: ();
      let _1: std::sync::Mutex<i32>;
      let mut _3: &std::sync::Mutex<i32>;
      let mut _5: &std::sync::Mutex<i32>;
      scope 1 {
          debug data => _1;
          let _2: std::result::Result<std::sync::MutexGuard<'_, i32>, std::sync::PoisonError<std::sync::MutexGuard<'_, i32>>>;
          scope 2 {
              debug _d1 => _2;
              let _4: std::result::Result<std::sync::MutexGuard<'_, i32>, std::sync::PoisonError<std::sync::MutexGuard<'_, i32>>>; 
              scope 3 {
                  debug _d2 => _4;
              }
          }
      }
  
      bb0: {
          _1 = Mutex::<i32>::new(const 0_i32) -> bb1;
      }
  
      bb1: {
          _3 = &_1;
          _2 = Mutex::<i32>::lock(move _3) -> bb2;
      }
  
      bb2: {
          _5 = &_1;
          _4 = Mutex::<i32>::lock(move _5) -> [return: bb3, unwind: bb6];
      }
  \end{minted}
  \caption{Un extracto de la MIR del programa del Listado \ref{lst:double-lock-deadlock}.}
  \label{lst:double-lock-deadlock-mir}
\end{listing}

Inmediatamente después de la sentencia, el traductor se encuentra con el terminator de BB1.
Contiene una llamada a \Rustinline{std::sync::Mutex::lock}. ¿Cómo sabría el traductor, al traducir esta
llamada, que \Rustinline{_3} es efectivamente el mutex almacenado en \Rustinline{_1}? Este es el problema que
pretende resolver el modelado de la memoria de la función.

El problema va aún más lejos. La variable local \Rustinline{_2} contiene un mutex guard después de la
llamada a lock, que también debería registrarse. Observe cómo BB2 repite las mismas
operaciones que BB1 pero utiliza variables locales diferentes, \Rustinline{_5} y \Rustinline{_4}. El traductor debería
saber que \Rustinline{_5} es también un alias de \Rustinline{_1}. Además, las guardas del mutex en \Rustinline{_2} y \Rustinline{_4} serán
eventualmente eliminados, lo que indirectamente desbloquea el mutex. Tiene que haber un
enlace desde la guarda de mutex en \Rustinline{_2} y \Rustinline{_4} al mutex en
\Rustinline{_1}. Más concisamente, el traductor debe supervisar qué mutex está detrás de cada guarda de mutex.

Para complejizar más las cosas, cada función MIR tiene su propia memoria de pila, con sus
variables locales separadas \Rustinline{_0}, \Rustinline{_1},
\Rustinline{_2}, \Rustinline{_3}, etcétera. Por lo tanto, la asignación de ubicaciones de
memoria a variables de sincronización no puede ser una única estructura global. En su lugar,
depende del contexto de la función actual que se esté traduciendo. Por último, una variable de
sincronización puede migrar de una función a otra y el traductor debe ser capaz de reasignarlas
correctamente.

Esto basta como breve ejemplo práctico de los retos que plantea el modelado de la memoria.
Ahora podemos presentar la solución que se ha aplicado.

\subsection{Una asignación de \texttt{rustc\_middle::mir::Place} a un contador de referencias compartido}

La implementación se denomina adecuadamente
\Rustinline{Memory}\footnote{\url{https://github.com/hlisdero/cargo-check-deadlock/blob/main/src/translator/mir_function/memory.rs}}.
Como se anticipó en la sección anterior,
La memoria está estrechamente conectada
al contexto de la función \acrshort{MIR}.

En lugar de mover valores entre distintas ubicaciones de memoria, como se observa en la \acrshort{MIR},
nuestra solución se basa en el concepto más sencillo de ``vinculación'' o ``enlazado''. Esto implica asociar un
\Rustinline{rustc_middle::mir::Place} específico con el valor correspondiente. Esta asociación no se elimina
al trasladar la variable a una función diferente. Tampoco diferencia una copia superficial del
valor de tomar una referencia o una referencia mutable. En pocas palabras, se trata de un
mapeo global entre lugares y valores.

Para dar cabida a la posibilidad de vincular el mismo valor a varios lugares, en particular
cuando varias posiciones de memoria mantienen una referencia inmutable al valor, se hace
necesario que el valor almacenado sea una referencia a la variable de sincronización. Para
aclararlo, esto introduce un segundo nivel de indirección. Para facilitar las operaciones de
clonación necesarias, hemos optado por utilizar \Rustinline{std::rc::Rc}, que es un puntero inteligente
proporcionado por la biblioteca estándar de Rust. La propiedad del valor referenciado (la
variable de sincronización) es compartida y cada vez que se clona el valor, se incrementa un
contador interno. Cuando el contador llega a cero, el valor se libera \cite[Chap. 15.4]{rust-book}.

La \Rustinline{Memory} hace uso de una estructura de datos \Rustinline{std::collections::HashMap}
que establece un mapeo entre instancias de \Rustinline{rustc_middle::mir::Place}
y un enum con 5 variantes correspondientes a
los 5 tipos mencionados anteriormente que el traductor rastrea. 4 de estas 5 variantes
encierran una referencia \Rustinline{std::rc::Rc} a la variable de sincronización. El caso de los agregados
contiene en cambio un vector de \Rustinline{Value}. Esto hace posible anidar valores agregados unos dentro de
otros, lo que es un requisito crítico para soportar programas más complejos con \Rustinline{structs}
anidados.

\begin{listing}[!htb]
  \begin{minted}{Rust}
    #[derive(Default)]
    pub struct Memory<'tcx> {
        map: HashMap<Place<'tcx>, Value>,
    }

    /// ...

    /// Possible values that can be stored in the `Memory`.
    /// A place will be mapped to one of these.
    #[derive(PartialEq, Clone)]
    pub enum Value {
        Mutex(MutexRef),
        MutexGuard(MutexGuardRef),
        JoinHandle(ThreadRef),
        Condvar(CondvarRef),
        Aggregate(Vec<Value>),
    }

    /// ...
    
    /// A mutex reference is just a shared pointer to the mutex.
    pub type MutexRef = std::rc::Rc<Mutex>;

    /// A mutex guard reference is just a shared pointer to the mutex guard.
    pub type MutexGuardRef = std::rc::Rc<MutexGuard>;

    /// A condvar reference is just a shared pointer to the condition variable.
    pub type CondvarRef = std::rc::Rc<Condvar>;

    /// A thread reference is just a shared pointer to the thread.
    pub type ThreadRef = std::rc::Rc<Thread>;
  \end{minted}
  \caption{Resumen de las definiciones de tipos de la implementación de \Rustinline{Memory}.}
  \label{lst:memory-implementation}
\end{listing}

El uso de un hash map permite recuperar y gestionar eficazmente los valores asociados
durante el proceso de traducción. La \Rustinline{Memory} también se encarga de proporcionar los typedefs
para las diferentes referencias a las variables de sincronización.
El Listado \ref{lst:memory-implementation} muestra un
pedazo del código fuente con las definiciones de tipos esenciales utilizadas en la
implementación. Las mejoras a la implementación actual se discuten en la Sec. \ref{sec:future-work-memory-model}.

\subsection{Interceptando asignaciones}
\label{sec:intercepting-assignments}

La pieza que falta en el rompecabezas del modelo de memoria es dónde enlazar exactamente las
posiciones de memoria. Hay tres lugares distintos en el código en los que esto tiene lugar.

Por un lado, las funciones traductoras encargadas de procesar los métodos de los mutexes, las
variables de condición y los hilos crean nuevas variables de sincronización que se vinculan al
valor de retorno del método correspondiente. Aquí comienza la vida útil de cada variable de
sincronización. Los detalles específicos se amplían en las Sec. \ref{sec:mutex-algorithms} y \ref{sec:condvar-algorithms}

Por otro lado, la variable de sincronización puede asignarse en cualquier otro \acrshort{BB}. Por esta
razón, el traductor incorpora una implementación personalizada del método \Rustinline{visit_assign}
para interceptar cada asignación en la \acrshort{MIR}.
El Listado \ref{lst:visit-assign} muestra con precisión que todos
los casos de copia, desplazamiento o referencia al lado derecho (\acrfull{RHS}) se gestionan
mediante el mismo mecanismo:
El lado izquierdo (\acrfull{LHS}) está vinculado al lado derecho (\acrfull{RHS}) si el tipo de la variable es una
variable de sincronización admitida. El listado también muestra cómo el compilador utiliza
enums anidados para modelar sus datos. Dentro de las variantes de un valor del lado derecho
(\Rustinline{rustc_middle::mir::Rvalue}), se pueden encontrar operandos (\Rustinline{rustc_middle::mir::Operand}).
Estos operandos también aparecen al pasar argumentos de función.

\begin{listing}[!htb]
  \begin{minted}{Rust}
    fn visit_assign(
        &mut self,
        place: &rustc_middle::mir::Place<'tcx>,
        rvalue: &rustc_middle::mir::Rvalue<'tcx>,
        location: rustc_middle::mir::Location,
    ) {
        match rvalue {
            rustc_middle::mir::Rvalue::Use(
                rustc_middle::mir::Operand::Copy(rhs) | rustc_middle::mir::Operand::Move(rhs),
            )
            | rustc_middle::mir::Rvalue::Ref(_, _, rhs) => {
                let function = self.call_stack.peek_mut();
                link_if_sync_variable(place, rhs, &mut function.memory, function.def_id, self.tcx);
            }
            rustc_middle::mir::Rvalue::Aggregate(_, operands) => {
                let function = self.call_stack.peek_mut();
                handle_aggregate_assignment(
                    place,
                    &operands.raw,
                    &mut function.memory,
                    function.def_id,
                    self.tcx,
                );
            }
            // No need to do anything for the other cases for now.
            _ => {}
        }

        self.super_assign(place, rvalue, location);
    }
  \end{minted}
  \caption{La implementación personalizada de \Rustinline{visit_assign} para rastrear variables de sincronización.}
  \label{lst:visit-assign}
\end{listing}

El caso más peculiar es la asignación agregada. Se materializa a partir de asignaciones en el
código fuente de Rust que crean tuplas, closures o \Rustinline{structs}. Requiere un manejo especial ya
que el valor a enlazar en la memoria debe ensamblarse a partir de los constituyentes del valor agregado que
son una variable de sincronización. Esto implica que la \Rustinline{Memory} sólo conserva la parte del valor
agregado formada por las variables de sincronización.

El seguimiento de las asignaciones de las variables de sincronización en el momento en que
son devueltas por las funciones es otro mecanismo crucial. Afortunadamente, esto puede
lograrse implementando una comprobación uniforme en todas las funciones,
independientemente de si se modelan utilizando el modelo simple (Fig. \ref{fig:simplest-function}) o el modelo de
función con limpieza (Fig. \ref{fig:function-with-cleanup}). Como ventaja, esta comprobación uniforme
soporta fácilmente \Rustinline{std::arc::Arc} sin necesidad de ningún esfuerzo adicional.

En todos los casos, el manejo de las asignaciones no tiene ningún impacto en la red de Petri.
No se añaden lugares ni transiciones al interceptar las asignaciones.

Por último, algunas posiciones de memoria se pasan a un nuevo hilo al llamar a
\Rustinline{std::thread::spawn} y se mapean de nuevo a la memoria de la función del hilo. La siguiente
sección demostrará el método utilizado para lograr esto.